version: '3.5'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    volumes:
      - zoo-stack-data:/tmp/zookeeper
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - 2181:2181
    networks:
      - kafka-net
    deploy:
      mode: global
      placement:
        constraints:
          - node.labels.zoo==1
    environment:
      -  "ZOOKEEPER_CLIENT_PORT=2181"

  kafka1:
    image: confluentinc/cp-kafka
    volumes:
       - kafka-stack-1-logs:/tmp/kafka-logs
       - /var/run/docker.sock:/var/run/docker.sock
    ports:
       - 9093:9093
    networks:
       - kafka-net
    deploy:
      mode: global
      placement:
        constraints:
          - node.labels.kafka==1
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: localhost:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9093

  kafka2:
    image: confluentinc/cp-kafka
    volumes:
       - kafka-stack-2-logs:/tmp/kafka-logs
       - /var/run/docker.sock:/var/run/docker.sock
    ports:
       - 9094:9094
    networks:
       - kafka-net
    deploy:
      mode: global
      placement:
        constraints:
          - node.labels.kafka==2
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: localhost:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9094

  kafka3:
    image: confluentinc/cp-kafka
    volumes:
       - kafka-stack-3-logs:/tmp/kafka-logs
       - /var/run/docker.sock:/var/run/docker.sock
    ports:
       - 9095:9095
    networks:
       - kafka-net
    deploy:
      mode: global
      placement:
        constraints:
          - node.labels.kafka==3
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: localhost:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9095

  twitter-producer:
    build:
      context: producerStream
      dockerfile: Dockerfile
    ports:
      - '12181:12181'
    networks:
      - kafka-net
    secrets:
      - consumer_key
      - consumer_secret
      - access_key
      - access_secret
    environment: 
      CONSUMER_KEY: /run/secrets/consumer_key
      CONSUMER_SECRET: /run/secrets/consumer_secret
      ACCESS_KEY: /run/secrets/access_key
      ACCESS_SECRET: /run/secrets/access_secret

  spark-master:
    build:
      context: streamProcessing
      dockerfile: Dockerfile
    links:
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "8888:8888"
      - "7077:7077"
    networks:
      - kafka-net
    environment:
      - INIT_DAEMON_STEP=setup_spark

  spark-worker-1:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    links:
      - spark-master
    ports:
      - "8081:8081"
    networks:
      - kafka-net
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"

networks:
  kafka-net:

secrets:
  consumer_key:
    external: true
  consumer_secret:
    external: true
  access_key:
    external: true
  access_secret:
    external: true

volumes:
  kafka-stack-1-logs:
  kafka-stack-2-logs:
  kafka-stack-3-logs:
  zoo-stack-data: